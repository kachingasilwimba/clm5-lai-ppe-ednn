{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6744d1-657b-4361-b951-7f7e82108031",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 08:45:30.822401: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-22 08:45:30.883224: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-22 08:45:32.098204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "    \n",
    "import os\n",
    "from model.pipeline import build_feature_matrix_and_target\n",
    "from data_processing.split import split_member_time\n",
    "from model.ednn_model import ednn_regressor_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570bc79d-10f5-44e0-939d-3e6b25fe6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c43462c-c8d9-42c1-9a27-140a022396ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full X, y shapes:          (19836000, 37) (19836000,)\n",
      "X_train_xr, X_val_xr:      (13780800, 37) (522000, 37)\n",
      "X_train, X_val:            (13780800, 37) (522000, 37)\n",
      "y_train_xr, y_val_xr:      (13780800,) (522000,)\n",
      "y_train, y_val:            (13780800, 1) (522000, 1)\n"
     ]
    }
   ],
   "source": [
    "#---------------- Build the full feature & target arrays\n",
    "X, y = build_feature_matrix_and_target()\n",
    "\n",
    "#---------------- Split & scale (returns 8 objects)\n",
    "(\n",
    "    X_train_xr, X_val_xr,\n",
    "    y_train_xr, y_val_xr,\n",
    "    X_train,    X_val,\n",
    "    y_train,    y_val\n",
    ") = split_member_time(X, y)\n",
    "\n",
    "#---------------- Sanity‚Äêcheck shapes\n",
    "print(\"Full X, y shapes:         \", X.shape, y.shape)\n",
    "print(\"X_train_xr, X_val_xr:     \", X_train_xr.shape, X_val_xr.shape)\n",
    "print(\"X_train, X_val:           \", X_train.shape, X_val.shape)\n",
    "print(\"y_train_xr, y_val_xr:     \", y_train_xr.shape, y_val_xr.shape)\n",
    "print(\"y_train, y_val:           \", y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfd336a-b19a-4ad4-bc3a-b1f5057a6ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.22982, saving model to /bsuhome/ksilwimba/scratch/emulation_with_forcing/clm5-lai-ppe-ednn/temporal_ppe_emulation/saved_model/ednn_reg_model4.keras\n",
      "11484/11484 - 56s - 5ms/step - loss: 1.0557 - mse: 3.9286 - val_loss: 1.2298 - val_mse: 3.9128 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 1.22982 to 1.21230, saving model to /bsuhome/ksilwimba/scratch/emulation_with_forcing/clm5-lai-ppe-ednn/temporal_ppe_emulation/saved_model/ednn_reg_model4.keras\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.9669 - mse: 6.7919 - val_loss: 1.2123 - val_mse: 5.5318 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 1.21230\n",
      "11484/11484 - 56s - 5ms/step - loss: 0.9370 - mse: 8.5268 - val_loss: 1.2431 - val_mse: 7.5973 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.9164 - mse: 9.7008 - val_loss: 1.2143 - val_mse: 9.8239 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.8995 - mse: 10.6900 - val_loss: 1.2377 - val_mse: 8.8689 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.8838 - mse: 11.7142 - val_loss: 1.2798 - val_mse: 11.3036 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.8690 - mse: 12.8764 - val_loss: 1.2832 - val_mse: 12.2077 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.21230\n",
      "11484/11484 - 50s - 4ms/step - loss: 0.8546 - mse: 13.9827 - val_loss: 1.3005 - val_mse: 13.2378 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.21230\n",
      "11484/11484 - 47s - 4ms/step - loss: 0.8409 - mse: 15.0296 - val_loss: 1.3656 - val_mse: 14.0625 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.21230\n",
      "11484/11484 - 44s - 4ms/step - loss: 0.8281 - mse: 16.4582 - val_loss: 1.4278 - val_mse: 16.1793 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.21230\n",
      "11484/11484 - 45s - 4ms/step - loss: 0.8162 - mse: 17.6080 - val_loss: 1.3787 - val_mse: 19.8048 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.8048 - mse: 18.8154 - val_loss: 1.4358 - val_mse: 18.7423 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.7940 - mse: 20.0840 - val_loss: 1.4592 - val_mse: 22.3251 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.7843 - mse: 21.0761 - val_loss: 1.5536 - val_mse: 26.6209 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.7748 - mse: 22.2623 - val_loss: 1.5075 - val_mse: 25.3553 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.7664 - mse: 23.5516 - val_loss: 1.6649 - val_mse: 35.8526 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.7586 - mse: 24.4829 - val_loss: 1.6372 - val_mse: 29.8508 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.7510 - mse: 25.2021 - val_loss: 1.4856 - val_mse: 26.9279 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.7439 - mse: 25.9233 - val_loss: 1.5338 - val_mse: 29.7071 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.7375 - mse: 26.4467 - val_loss: 1.6205 - val_mse: 42.2623 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.7314 - mse: 27.1086 - val_loss: 1.5234 - val_mse: 34.7151 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.7258 - mse: 27.6552 - val_loss: 1.6006 - val_mse: 40.2484 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.7203 - mse: 28.0845 - val_loss: 1.6139 - val_mse: 30.4002 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.7152 - mse: 28.5914 - val_loss: 1.7082 - val_mse: 38.4175 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.21230\n",
      "11484/11484 - 56s - 5ms/step - loss: 0.7103 - mse: 29.1039 - val_loss: 1.7569 - val_mse: 45.1691 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.21230\n",
      "11484/11484 - 56s - 5ms/step - loss: 0.7057 - mse: 29.5869 - val_loss: 1.5776 - val_mse: 32.3086 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.7013 - mse: 30.1481 - val_loss: 1.6361 - val_mse: 45.0690 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.6016 - mse: 35.7121 - val_loss: 2.1367 - val_mse: 50.9928 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.5888 - mse: 41.2626 - val_loss: 2.0435 - val_mse: 54.7293 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.5808 - mse: 44.6991 - val_loss: 2.1721 - val_mse: 67.7872 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.5742 - mse: 47.5394 - val_loss: 2.2924 - val_mse: 65.6969 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.5685 - mse: 49.7982 - val_loss: 2.4469 - val_mse: 74.6409 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.5636 - mse: 51.5360 - val_loss: 2.2666 - val_mse: 71.9227 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 1.21230\n",
      "11484/11484 - 52s - 5ms/step - loss: 0.5593 - mse: 53.4772 - val_loss: 2.2882 - val_mse: 80.0512 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 1.21230\n",
      "11484/11484 - 48s - 4ms/step - loss: 0.5552 - mse: 55.3962 - val_loss: 2.1715 - val_mse: 87.3391 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 36: val_loss did not improve from 1.21230\n",
      "11484/11484 - 45s - 4ms/step - loss: 0.5517 - mse: 57.3436 - val_loss: 2.4100 - val_mse: 88.4977 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 1.21230\n",
      "11484/11484 - 45s - 4ms/step - loss: 0.5482 - mse: 59.2298 - val_loss: 2.2941 - val_mse: 84.3524 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.5452 - mse: 61.0254 - val_loss: 2.5262 - val_mse: 93.6329 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 39: val_loss did not improve from 1.21230\n",
      "11484/11484 - 51s - 4ms/step - loss: 0.5422 - mse: 62.7242 - val_loss: 2.4644 - val_mse: 88.7248 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\n",
      "Epoch 40: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.5395 - mse: 64.2756 - val_loss: 2.5221 - val_mse: 89.7175 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\n",
      "Epoch 41: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.5370 - mse: 65.6264 - val_loss: 2.3957 - val_mse: 99.4630 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\n",
      "Epoch 42: val_loss did not improve from 1.21230\n",
      "11484/11484 - 53s - 5ms/step - loss: 0.5345 - mse: 66.9507 - val_loss: 2.3660 - val_mse: 86.4301 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\n",
      "Epoch 43: val_loss did not improve from 1.21230\n",
      "11484/11484 - 52s - 5ms/step - loss: 0.5324 - mse: 68.0698 - val_loss: 2.4864 - val_mse: 102.6232 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\n",
      "Epoch 44: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.5301 - mse: 69.5951 - val_loss: 2.6164 - val_mse: 100.9975 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\n",
      "Epoch 45: val_loss did not improve from 1.21230\n",
      "11484/11484 - 52s - 5ms/step - loss: 0.5281 - mse: 70.4986 - val_loss: 2.7334 - val_mse: 90.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\n",
      "Epoch 46: val_loss did not improve from 1.21230\n",
      "11484/11484 - 55s - 5ms/step - loss: 0.5260 - mse: 71.1382 - val_loss: 2.3532 - val_mse: 95.4631 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\n",
      "Epoch 47: val_loss did not improve from 1.21230\n",
      "11484/11484 - 54s - 5ms/step - loss: 0.5241 - mse: 72.1415 - val_loss: 2.6614 - val_mse: 100.8861 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n"
     ]
    }
   ],
   "source": [
    "# model_folder = \"/bsuhome/ksilwimba/scratch/clm5-lai-ppe-ednn/temporal_ppe_emulation/saved_model\"\n",
    "model_folder = \"/bsuhome/ksilwimba/scratch/emulation_with_forcing/clm5-lai-ppe-ednn/temporal_ppe_emulation/saved_model\"\n",
    "\n",
    "#---------- Train  Annual Model\n",
    "model_path = model_folder+\"/ednn_reg_model4.keras\"\n",
    "\n",
    "p_wu_val, p_wo_val, p_wu_train, p_wo_train, model, hist = ednn_regressor_model(\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    model_path=model_path,#\"ednn_best.keras\",\n",
    "    hidden_layers=6,\n",
    "    hidden_neurons=128,#64,32\n",
    "    activation='leaky_relu',#'leaky_relu'\n",
    "    l2_weight=0.00071073,\n",
    "    dropout_alpha=0.1,\n",
    "    use_dropout=False,\n",
    "    use_noise=False,\n",
    "    noise_sd=0.1,\n",
    "    loss_weight=1e-10,#8,10\n",
    "    learning_rate=0.00018102,\n",
    "    batch_size=1200,\n",
    "    epochs=100,\n",
    "    patience=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44822e50-f75f-4b74-b49a-7bb2f44a7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_paths=None, figsize=(8, 5)):\n",
    "    \"\"\"\n",
    "    Plot training mean squared error (MSE) and loss over epochs.\n",
    "\n",
    "    Args:\n",
    "        history: Keras History object returned by model.fit().\n",
    "        save_paths: Optional dict with keys 'mse' and 'loss' mapping to file paths\n",
    "                    to save the respective figures. If None, figures are not saved.\n",
    "        figsize: Tuple specifying figure size.\n",
    "    \"\"\"\n",
    "    #------------- Extract epoch indices\n",
    "    epochs = history.epoch\n",
    "    #------------- Extract metric values\n",
    "    train_mse = history.history.get('mse', [])\n",
    "    val_loss = history.history.get('loss', [])\n",
    "\n",
    "    #------------- Plot Mean Squared Error over epochs\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(\n",
    "        epochs,\n",
    "        train_mse,\n",
    "        label='Train MSE',\n",
    "        marker='o',\n",
    "        linestyle='--',\n",
    "        linewidth=2\n",
    "    )\n",
    "    plt.title('ANN Training: Mean Squared Error', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Mean Squared Error', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(shadow=True, edgecolor='black')\n",
    "    if save_paths and 'mse' in save_paths:\n",
    "        plt.savefig(save_paths['mse'], bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    #------------- Plot Loss over epochs\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(\n",
    "        epochs,\n",
    "        val_loss,\n",
    "        label='Validation Loss',\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        linewidth=2\n",
    "    )\n",
    "    plt.title('ANN Training: Loss', fontsize=13)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Loss', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(shadow=True, edgecolor='black')\n",
    "    if save_paths and 'loss' in save_paths:\n",
    "        plt.savefig(save_paths['loss'], bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf42ca-c64d-463c-839c-81bc448af36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_training_history(hist, save_paths={'mse': 'mse.png', 'loss': 'loss.png'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d1378-7648-435b-9be8-729b71e8ae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xesmf_env2",
   "language": "python",
   "name": "xesmf_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
